{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec873f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baza = pd.read_csv(\"utitles_cats.tsv\", sep=\"\\t\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f594854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим несколько строк датафрейма и его размерность\n",
    "\n",
    "df_baza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим сколько пустых значений содержат колонки нашего датафрейма\n",
    "\n",
    "df_baza.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64db578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим строки, где в колонке \"is_drug\" стоит значение \"False\"\n",
    "mask = df_baza['is_drug'] == 'False'\n",
    "df_baza.drop(df_baza[mask].index, inplace=True)\n",
    "\n",
    "# там, где не указан manuf_cat, перенесем данные из колонки manuf\n",
    "df_baza['manuf_cat'].fillna(df_baza['manuf'], inplace=True)\n",
    "\n",
    "# удаляем строки, где содержатся пустые значения в колонках title, manuf, title_cat, manuf_cat\n",
    "df_baza = df_baza.loc[df_baza['manuf_cat'] != 0]\n",
    "df_baza.dropna(subset=['title', 'title_cat', 'manuf_cat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baza.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# организуем процесс выборки из массива данных 1500 уникальных категорий и по каждой из категорий возьмем от 4 до 20 значений title,\n",
    "# при этом первое значение title - будет использоваться в списке аптеки,\n",
    "# второй значение title для той же категории - будет использоваться в списке поставщика\n",
    "# остальные значения title для той же категории - будут использоваться в списке study для проведения обучения.\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "duplicates = df_baza[df_baza.duplicated('title', keep=False)]\n",
    "unique_titles = duplicates.drop_duplicates('title')['title'].tolist()\n",
    "\n",
    "indexes_to_drop = df_baza[df_baza['title'].isin(unique_titles)].index\n",
    "\n",
    "df_baza_unique = df_baza.drop(indexes_to_drop)\n",
    "\n",
    "categories_with_enough_titles = df_baza_unique.groupby('title_cat').filter(lambda x: len(x) >= 4)\n",
    "\n",
    "random_categories = categories_with_enough_titles['title_cat'].drop_duplicates().sample(n=1500, random_state=1)\n",
    "\n",
    "df = pd.DataFrame() \n",
    "\n",
    "for cat in tqdm(random_categories, desc='Фильтрация категорий'):\n",
    "    sampled_df = df_baza_unique[df_baza_unique['title_cat'] == cat].sample(n=min(20, len(df_baza_unique[df_baza_unique['title_cat'] == cat])), random_state=1)\n",
    "    df = pd.concat([df, sampled_df], ignore_index=True)\n",
    "\n",
    "# Проверяем, достигнуто ли требуемое количество уникальных категорий\n",
    "if len(df['title_cat'].unique()) == 1500:\n",
    "    print('Требуемое количество уникальных категорий достигнуто')\n",
    "else:\n",
    "    print('Требуемое количество уникальных категорий не достигнуто: ', len(df['title_cat'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проводим предобработку данных (в части знаков препинания и лишних пробелов)\n",
    "\n",
    "import re\n",
    "import string\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def replace_punctuation(title):\n",
    "    title = re.sub(r'[^\\w\\s]', '.', title)\n",
    "    title = re.sub(r'\\.{2,}', '.', title)\n",
    "    return title\n",
    "\n",
    "def remove_multiple_spaces(title):\n",
    "    return re.sub(r'\\s+', ' ', title, flags=re.I)\n",
    "\n",
    "df['title'] = df['title'].progress_apply(lambda title: remove_multiple_spaces(replace_punctuation(title)).lower())\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6543f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# дополнительно проведем предобработку данных по стоп-словам с добавлением в список слов \"акция\", \"скидка\", \"подарок\", 'внимание', 'неопознанный'\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Загрузка стоп-слов для русского языка, добавление в стоп-слова слов \"акция\", \"скидка\", \"подарок\", 'внимание', 'неопознанный'\n",
    "russian_stopwords = stopwords.words('russian')\n",
    "russian_stopwords.extend(['скидка', 'подарок', 'акция','внимание', 'неопознанный'])\n",
    "\n",
    "def filter_tokens(tokens):\n",
    "    return [token for token in tokens if token not in russian_stopwords and token != ' ']\n",
    "\n",
    "df['title'] = df['title'].progress_apply(lambda title: \" \".join(filter_tokens(word_tokenize(title, language='russian'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578eb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f81482",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2956517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала разделим датафрейм на 3 части по каждой категории.\n",
    "# Затем создадим три словаря: 1 - список аптеки, 2 - список поставщика, 3 - список для обучения модели (train),\n",
    "# где каждый словарь будет содержать уникальные пары title_cat: title.\n",
    "\n",
    "# После этого создадим четвертый словарь, где ключом будет title из первого словаря (список аптеки), \n",
    "# а значением - соответствующий title из второго словаря (список поставщика). \n",
    "# Этот словарь будет использоваться для оценки корректности сопоставления.\n",
    "\n",
    "grouped = df.groupby('title_cat')\n",
    "pharmacy_map, supplier_map, study_dict = {}, {}, {} # 1 - список аптеки, 2 - список поставщика, 3 - список для обучения модели\n",
    "#четвертый словарь, который связывает title из первого словаря (аптеки) с title из второго (поставщика) по той же категории\n",
    "title_to_title_true = {}\n",
    "\n",
    "for name, group in grouped:\n",
    "    titles = group['title'].tolist()\n",
    "   \n",
    "    if len(titles) > 2:\n",
    "        pharmacy_map[name] = titles[0]\n",
    "        supplier_map[name] = titles[1]\n",
    "        \n",
    "        study_dict[name] = titles[2:]\n",
    "        title_to_title_true[titles[0]] = titles[1]\n",
    "    else:\n",
    "        \n",
    "        continue\n",
    "\n",
    "for name, group in grouped:\n",
    "    titles = group['title'].tolist()\n",
    "    pharmacy_map[name] = titles[0]\n",
    "\n",
    "supplier_map[name] = titles[1] if len(titles) > 1 else None\n",
    "\n",
    "study_dict[name] = titles[2:] if len(titles) > 2 else []\n",
    "\n",
    "if supplier_map[name] is not None:\n",
    "    title_to_title_true[titles[0]] = supplier_map[name]\n",
    "\n",
    "list1_title_cat = list(pharmacy_map.keys())\n",
    "list1_title = list(pharmacy_map.values())\n",
    "\n",
    "list2_title_cat = list(supplier_map.keys())\n",
    "list2_title = list(supplier_map.values())\n",
    "\n",
    "list3_title_cat = []\n",
    "list3_title = []\n",
    "\n",
    "for cat, titles in study_dict.items():\n",
    "    list3_title_cat.extend([cat] * len(titles))\n",
    "    list3_title.extend(titles)\n",
    "\n",
    "pharmacy_list = list(pharmacy_map.items())\n",
    "supplier_list = list(supplier_map.items())\n",
    "study_list = [(cat, title) for cat, titles in study_dict.items() for title in titles]\n",
    "title_to_title_true_list = list(title_to_title_true.items())\n",
    "\n",
    "pharmacy_df = pd.DataFrame(pharmacy_list, columns=['title_cat', 'title'])\n",
    "supplier_df = pd.DataFrame(supplier_list, columns=['title_cat', 'title'])\n",
    "study_df = pd.DataFrame(study_list, columns=['title_cat', 'title'])\n",
    "title_to_title_true_df = pd.DataFrame(title_to_title_true_list, columns=['Ключ', 'Значение'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим как выглядит словарь для списка аптеки\n",
    "\n",
    "pharmacy_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pharmacy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9dafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим как выглядит словарь для списка поставщика\n",
    "\n",
    "supplier_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bb107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим как выглядит словарь для списка для обучения модели\n",
    "\n",
    "study_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим как выглядит словарь, который связывает title из первого словаря (аптеки) с title из второго словаря (поставщика) \n",
    "# по той же категории\n",
    "\n",
    "title_to_title_true_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_to_title_true_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead25cc",
   "metadata": {},
   "source": [
    "# Определение train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4734467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в качестве train используем ранее созданный список study (он имеет title и title_cat)\n",
    "# затем после обучения предсказываем категорию для списка аптеки и списка поставщика\n",
    "\n",
    "X_train = list3_title # title из списка study\n",
    "y_train = list3_title_cat # title_cat из списка study\n",
    "X_test_1 = list1_title # title из списка аптеки\n",
    "X_test_2 = list2_title # title из списка поставщика\n",
    "y_test_1 = list1_title_cat # title_cat из списка аптеки \n",
    "y_test_2 = list2_title_cat # title_cat из списка поставщика "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477de613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление неиспользуемого df с целью экономии памяти\n",
    "\n",
    "import gc\n",
    "\n",
    "# Удаление DataFrame\n",
    "del df_baza\n",
    "\n",
    "# Вызов сборщика мусора\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce41b934",
   "metadata": {},
   "source": [
    "# Наивный байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "start_time = time.time()\n",
    "start_memory = process.memory_info().rss\n",
    "\n",
    "nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "end_memory = process.memory_info().rss  \n",
    "\n",
    "y_pred_nb_1 = nb.predict(X_test_1)\n",
    "y_pred_nb_2 = nb.predict(X_test_2)\n",
    "\n",
    "print('\\nВремя, затраченное на обучение модели: ', end_time - start_time, ' секунд')\n",
    "print(f\"Использовано памяти: {end_memory - start_memory} байт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет Accuracy Score (долю правильно предсказанных наблюдений от общего числа наблюдений)\n",
    "accuracy_1 = round(accuracy_score(y_test_1, y_pred_nb_1), 2)\n",
    "accuracy_2 = round(accuracy_score(y_test_2, y_pred_nb_2), 2)\n",
    "\n",
    "# Расчет Precision (Точность) (доля правильно идентифицированных положительных результатов из всех результатов, которые были классифицированы как положительные)\n",
    "precision_1 = round(precision_score(y_test_1, y_pred_nb_1, average='weighted', zero_division=0), 2)\n",
    "precision_2 = round(precision_score(y_test_2, y_pred_nb_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет Recall (Полнота) (доля правильно идентифицированных положительных результатов из всех реальных положительных результатов)\n",
    "recall_1 = round(recall_score(y_test_1, y_pred_nb_1, average='weighted', zero_division=0), 2)\n",
    "recall_2 = round(recall_score(y_test_2, y_pred_nb_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет F1-score (гармоническое среднее между точностью и полнотой)\n",
    "f1_1 = round(f1_score(y_test_1, y_pred_nb_1, average='weighted', zero_division=0), 2)\n",
    "f1_2 = round(f1_score(y_test_2, y_pred_nb_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "print('Метрики для списка аптеки')\n",
    "print('Accuracy score: ', accuracy_1)\n",
    "print('Precision: ', precision_1)\n",
    "print('Recall: ', recall_1)\n",
    "print('F1-score: ', f1_1)\n",
    "\n",
    "print('\\nМетрики для списка поставщика')\n",
    "print('Accuracy score: ', accuracy_2)\n",
    "print('Precision: ', precision_2)\n",
    "print('Recall: ', recall_2)\n",
    "print('F1-score: ', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726684a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_1, y_pred_nb_1, y_test_1 в виде датафрейма\n",
    "comparison_df_nb_1 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_1[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_nb_1[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_1[:10]\n",
    "})\n",
    "comparison_df_nb_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_2, y_pred_nb_2, y_test_2 в виде датафрейма\n",
    "comparison_df_nb_2 = pd.DataFrame({\n",
    "    'Имеющийся title из списка поставщика': X_test_2[:10],\n",
    "    'Прогнозируемая категория для списка поставщика': y_pred_nb_2[:10],\n",
    "    'Фактическая категория для списка поставщика': y_test_2[:10]\n",
    "})\n",
    "comparison_df_nb_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет количества совпадений\n",
    "matches = sum(1 for i, j in zip(y_pred_nb_1, y_pred_nb_2) if i == j)\n",
    "\n",
    "# Расчет процента совпадений\n",
    "matches_percentage = round((matches / len(y_pred_nb_1)) * 100, 2)\n",
    "\n",
    "print('Процент совпадений: ', matches_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31958559",
   "metadata": {},
   "source": [
    "# Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление неиспользуемой переменной с предыдущего этапа обучения с целью экономии памяти\n",
    "\n",
    "import gc\n",
    "\n",
    "del nb\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "start_time = time.time()\n",
    "start_memory = process.memory_info().rss \n",
    "\n",
    "dt = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "end_memory = process.memory_info().rss  \n",
    "\n",
    "y_pred_dt_1 = dt.predict(X_test_1)\n",
    "y_pred_dt_2 = dt.predict(X_test_2)\n",
    "\n",
    "print('\\nВремя, затраченное на обучение модели: ', end_time - start_time, ' секунд')\n",
    "print(f\"Использовано памяти: {end_memory - start_memory} байт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет Accuracy Score (долю правильно предсказанных наблюдений от общего числа наблюдений)\n",
    "accuracy_1 = round(accuracy_score(y_test_1, y_pred_dt_1), 2)\n",
    "accuracy_2 = round(accuracy_score(y_test_2, y_pred_dt_2), 2)\n",
    "\n",
    "# Расчет Precision (Точность) (доля правильно идентифицированных положительных результатов из всех результатов, которые были классифицированы как положительные)\n",
    "precision_1 = round(precision_score(y_test_1, y_pred_dt_1, average='weighted', zero_division=0), 2)\n",
    "precision_2 = round(precision_score(y_test_2, y_pred_dt_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет Recall (Полнота) (доля правильно идентифицированных положительных результатов из всех реальных положительных результатов)\n",
    "recall_1 = round(recall_score(y_test_1, y_pred_dt_1, average='weighted', zero_division=0), 2)\n",
    "recall_2 = round(recall_score(y_test_2, y_pred_dt_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет F1-score (гармоническое среднее между точностью и полнотой)\n",
    "f1_1 = round(f1_score(y_test_1, y_pred_dt_1, average='weighted', zero_division=0), 2)\n",
    "f1_2 = round(f1_score(y_test_2, y_pred_dt_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "print('Метрики для списка аптеки')\n",
    "print('Accuracy score: ', accuracy_1)\n",
    "print('Precision: ', precision_1)\n",
    "print('Recall: ', recall_1)\n",
    "print('F1-score: ', f1_1)\n",
    "\n",
    "print('\\nМетрики для списка поставщика')\n",
    "print('Accuracy score: ', accuracy_2)\n",
    "print('Precision: ', precision_2)\n",
    "print('Recall: ', recall_2)\n",
    "print('F1-score: ', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ca3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_1, y_pred_dt_1, y_test_1 в виде датафрейма\n",
    "comparison_df_dt_1 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_1[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_dt_1[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_1[:10]\n",
    "})\n",
    "comparison_df_dt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_2, y_pred_dt_2, y_test_2 в виде датафрейма\n",
    "comparison_df_dt_2 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_2[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_dt_2[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_2[:10]\n",
    "})\n",
    "comparison_df_dt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fafdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет количества совпадений\n",
    "matches = sum(1 for i, j in zip(y_pred_dt_1, y_pred_dt_2) if i == j)\n",
    "\n",
    "# Расчет процента совпадений\n",
    "matches_percentage = round((matches / len(y_pred_dt_1)) * 100, 2)\n",
    "\n",
    "print('Процент совпадений: ', matches_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6fe1d",
   "metadata": {},
   "source": [
    "# Вывод списка поставщиков по предсказанным категориям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_title_cat это предсказанные ранее категории по списку аптеки (в результате обучения DT)\n",
    "predict_title_cat = y_pred_dt_1 \n",
    "\n",
    "pharmacy_df_new = pd.DataFrame(predict_title_cat, columns=['predict_title_cat'])\n",
    "merged_df = pharmacy_df_new.merge(df, left_on='predict_title_cat', right_on='title_cat', how='left')\n",
    "suppliers_per_cat = merged_df.groupby('predict_title_cat')['manuf_cat'].unique()\n",
    "\n",
    "suppliers_list = pd.DataFrame({'Категория': suppliers_per_cat.index, \n",
    "                               'Поставщики': [', '.join(suppliers) for suppliers in suppliers_per_cat.values]\n",
    "                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328776e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppliers_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae3d11",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0654417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление неиспользуемой переменной с предыдущего этапа обучения с целью экономии памяти\n",
    "\n",
    "import gc\n",
    "\n",
    "del dt\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "start_time = time.time()\n",
    "start_memory = process.memory_info().rss \n",
    "\n",
    "rf = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', RandomForestClassifier())\n",
    "              ])\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "end_memory = process.memory_info().rss \n",
    "\n",
    "y_pred_rf_1 = rf.predict(X_test_1)\n",
    "y_pred_rf_2 = rf.predict(X_test_2)\n",
    "\n",
    "print(f\"Время выполнения: {end_time - start_time} секунд\")\n",
    "print(f\"Использовано памяти: {end_memory - start_memory} байт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет Accuracy Score (долю правильно предсказанных наблюдений от общего числа наблюдений)\n",
    "accuracy_1 = round(accuracy_score(y_test_1, y_pred_rf_1), 2)\n",
    "accuracy_2 = round(accuracy_score(y_test_2, y_pred_rf_2), 2)\n",
    "\n",
    "# Расчет Precision (Точность) (доля правильно идентифицированных положительных результатов из всех результатов, которые были классифицированы как положительные)\n",
    "precision_1 = round(precision_score(y_test_1, y_pred_rf_1, average='weighted', zero_division=0), 2)\n",
    "precision_2 = round(precision_score(y_test_2, y_pred_rf_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет Recall (Полнота) (доля правильно идентифицированных положительных результатов из всех реальных положительных результатов)\n",
    "recall_1 = round(recall_score(y_test_1, y_pred_rf_1, average='weighted', zero_division=0), 2)\n",
    "recall_2 = round(recall_score(y_test_2, y_pred_rf_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет F1-score (гармоническое среднее между точностью и полнотой)\n",
    "f1_1 = round(f1_score(y_test_1, y_pred_rf_1, average='weighted', zero_division=0), 2)\n",
    "f1_2 = round(f1_score(y_test_2, y_pred_rf_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "print('Метрики для списка аптеки')\n",
    "print('Accuracy score: ', accuracy_1)\n",
    "print('Precision: ', precision_1)\n",
    "print('Recall: ', recall_1)\n",
    "print('F1-score: ', f1_1)\n",
    "\n",
    "print('\\nМетрики для списка поставщика')\n",
    "print('Accuracy score: ', accuracy_2)\n",
    "print('Precision: ', precision_2)\n",
    "print('Recall: ', recall_2)\n",
    "print('F1-score: ', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9805d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_1, y_pred_rf_1, y_test_1 в виде датафрейма\n",
    "comparison_df_rf_1 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_1[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_rf_1[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_1[:10]\n",
    "})\n",
    "comparison_df_rf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_2, y_pred_rf_2, y_test_2 в виде датафрейма\n",
    "comparison_df_rf_2 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_2[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_rf_2[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_2[:10]\n",
    "})\n",
    "comparison_df_rf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbdbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет количества совпадений\n",
    "matches = sum(1 for i, j in zip(y_pred_rf_1, y_pred_rf_2) if i == j)\n",
    "\n",
    "# Расчет процента совпадений\n",
    "matches_percentage = round((matches / len(y_pred_rf_1)) * 100, 2)\n",
    "\n",
    "print('Процент совпадений: ', matches_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb945eb8",
   "metadata": {},
   "source": [
    "# Метод ближайших соседей KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление неиспользуемой переменной с предыдущего этапа обучения с целью экономии памяти\n",
    "\n",
    "import gc\n",
    "\n",
    "del rf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор параметра n_neighbours\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "k_values = range(1, 21)\n",
    "cross_val_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_tfidf, y_train, cv=5)\n",
    "    cross_val_scores.append(scores.mean())\n",
    "\n",
    "optimal_k = k_values[cross_val_scores.index(max(cross_val_scores))]\n",
    "print('Оптимальное значение K: ', optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650930f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "start_time = time.time()\n",
    "start_memory = process.memory_info().rss \n",
    "\n",
    "knn = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "end_memory = process.memory_info().rss \n",
    "\n",
    "y_pred_knn_1 = knn.predict(X_test_1)\n",
    "y_pred_knn_2 = knn.predict(X_test_2)\n",
    "\n",
    "print('\\nВремя, затраченное на обучение модели: ', end_time - start_time, ' секунд')\n",
    "print(f\"Использовано памяти: {end_memory - start_memory} байт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8110e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет Accuracy Score (долю правильно предсказанных наблюдений от общего числа наблюдений)\n",
    "accuracy_1 = round(accuracy_score(y_test_1, y_pred_knn_1), 2)\n",
    "accuracy_2 = round(accuracy_score(y_test_2, y_pred_knn_2), 2)\n",
    "\n",
    "# Расчет Precision (Точность) (доля правильно идентифицированных положительных результатов из всех результатов, которые были классифицированы как положительные)\n",
    "precision_1 = round(precision_score(y_test_1, y_pred_knn_1, average='weighted', zero_division=0), 2)\n",
    "precision_2 = round(precision_score(y_test_2, y_pred_knn_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет Recall (Полнота) (доля правильно идентифицированных положительных результатов из всех реальных положительных результатов)\n",
    "recall_1 = round(recall_score(y_test_1, y_pred_knn_1, average='weighted', zero_division=0), 2)\n",
    "recall_2 = round(recall_score(y_test_2, y_pred_knn_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет F1-score (гармоническое среднее между точностью и полнотой)\n",
    "f1_1 = round(f1_score(y_test_1, y_pred_knn_1, average='weighted', zero_division=0), 2)\n",
    "f1_2 = round(f1_score(y_test_2, y_pred_knn_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Выводим результаты\n",
    "print('Метрики для списка аптеки')\n",
    "print('Accuracy score: ', accuracy_1)\n",
    "print('Precision: ', precision_1)\n",
    "print('Recall: ', recall_1)\n",
    "print('F1-score: ', f1_1)\n",
    "\n",
    "print('\\nМетрики для списка поставщика')\n",
    "print('Accuracy score: ', accuracy_2)\n",
    "print('Precision: ', precision_2)\n",
    "print('Recall: ', recall_2)\n",
    "print('F1-score: ', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ce5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_1, y_pred_knn_1, y_test_1 в виде датафрейма\n",
    "comparison_df_knn_1 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_1[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_knn_1[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_1[:10]\n",
    "})\n",
    "comparison_df_knn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_2, y_pred_knn_2, y_test_2 в виде датафрейма\n",
    "comparison_df_knn_2 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_2[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_knn_2[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_2[:10]\n",
    "})\n",
    "comparison_df_knn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eaf760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет количества совпадений\n",
    "matches = sum(1 for i, j in zip(y_pred_knn_1, y_pred_knn_2) if i == j)\n",
    "\n",
    "# Расчет процента совпадений\n",
    "matches_percentage = round((matches / len(y_pred_knn_1)) * 100, 2)\n",
    "\n",
    "print('Процент совпадений: ', matches_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d77f3",
   "metadata": {},
   "source": [
    "# Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del knn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f2020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "start_time = time.time()\n",
    "start_memory = process.memory_info().rss\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "end_memory = process.memory_info().rss \n",
    "\n",
    "y_pred_svm_1 = svm_pipeline.predict(X_test_1)\n",
    "y_pred_svm_2 = svm_pipeline.predict(X_test_2)\n",
    "\n",
    "print('\\nВремя, затраченное на обучение модели: ', end_time - start_time, ' секунд')\n",
    "print(f\"Использовано памяти: {end_memory - start_memory} байт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3020be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет Accuracy Score (долю правильно предсказанных наблюдений от общего числа наблюдений)\n",
    "accuracy_1 = round(accuracy_score(y_test_1, y_pred_svm_1), 2)\n",
    "accuracy_2 = round(accuracy_score(y_test_2, y_pred_svm_2), 2)\n",
    "\n",
    "# Расчет Precision (Точность) (доля правильно идентифицированных положительных результатов из всех результатов, которые были классифицированы как положительные)\n",
    "precision_1 = round(precision_score(y_test_1, y_pred_svm_1, average='weighted', zero_division=0), 2)\n",
    "precision_2 = round(precision_score(y_test_2, y_pred_svm_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет Recall (Полнота) (доля правильно идентифицированных положительных результатов из всех реальных положительных результатов)\n",
    "recall_1 = round(recall_score(y_test_1, y_pred_svm_1, average='weighted', zero_division=0), 2)\n",
    "recall_2 = round(recall_score(y_test_2, y_pred_svm_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Расчет F1-score (гармоническое среднее между точностью и полнотой)\n",
    "f1_1 = round(f1_score(y_test_1, y_pred_svm_1, average='weighted', zero_division=0), 2)\n",
    "f1_2 = round(f1_score(y_test_2, y_pred_svm_2, average='weighted', zero_division=0), 2)\n",
    "\n",
    "# Выводим результаты\n",
    "print('Метрики для списка аптеки')\n",
    "print('Accuracy score: ', accuracy_1)\n",
    "print('Precision: ', precision_1)\n",
    "print('Recall: ', recall_1)\n",
    "print('F1-score: ', f1_1)\n",
    "\n",
    "print('\\nМетрики для списка поставщика')\n",
    "print('Accuracy score: ', accuracy_2)\n",
    "print('Precision: ', precision_2)\n",
    "print('Recall: ', recall_2)\n",
    "print('F1-score: ', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_1, y_pred_svm_1, y_test_1 в виде датафрейма\n",
    "comparison_df_svm_1 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_1[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_svm_1[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_1[:10]\n",
    "})\n",
    "comparison_df_svm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715797a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим визуально первые 10 строк X_test_2, y_pred_svm_2, y_test_2 в виде датафрейма\n",
    "comparison_df_svm_2 = pd.DataFrame({\n",
    "    'Имеющийся title из списка аптеки': X_test_2[:10],\n",
    "    'Прогнозируемая категория для списка аптеки': y_pred_svm_2[:10],\n",
    "    'Фактическая категория для списка аптеки': y_test_2[:10]\n",
    "})\n",
    "comparison_df_svm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12baadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет количества совпадений\n",
    "matches = sum(1 for i, j in zip(y_pred_svm_1, y_pred_svm_2) if i == j)\n",
    "\n",
    "# Расчет процента совпадений\n",
    "matches_percentage = round((matches / len(y_pred_svm_1)) * 100, 2)\n",
    "\n",
    "print('Процент сопоставлений: ', matches_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27353874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление неиспользуемой переменной с предыдущего этапа обучения с целью экономии памяти\n",
    "\n",
    "import gc\n",
    "\n",
    "del svm_pipeline\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769babe6",
   "metadata": {},
   "source": [
    "# Решение задачи сопоставления с помощью TF-IDF и косинусного сходства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "start_time = time.time()\n",
    "start_memory = process.memory_info().rss\n",
    "\n",
    "vectorizer = TfidfVectorizer().fit(list1_title + list2_title)\n",
    "tfidf_matrix1 = vectorizer.transform(list1_title)\n",
    "tfidf_matrix2 = vectorizer.transform(list2_title)\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix1, tfidf_matrix2)\n",
    "\n",
    "print('Косинусные сходства:')\n",
    "print(cosine_similarities)\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    predicted_pairs = []\n",
    "    for i in range(len(list1_title)):\n",
    "        for j in range(len(list2_title)):\n",
    "            if cosine_similarities[i, j] >= threshold:\n",
    "                predicted_pairs.append((list1_title[i], list2_title[j]))\n",
    "\n",
    "    \n",
    "    predicted_df = pd.DataFrame(predicted_pairs, columns=['Ключ', 'Значение']).drop_duplicates()\n",
    "    \n",
    "    true_positive_df = predicted_df.merge(title_to_title_true_df, on=['Ключ', 'Значение'], how='inner')\n",
    "    false_positive_df = predicted_df.merge(title_to_title_true_df, on=['Ключ', 'Значение'], how='left', indicator=True)\n",
    "    false_negative_df = title_to_title_true_df.merge(predicted_df, on=['Ключ', 'Значение'], how='left', indicator=True)\n",
    "\n",
    "    true_positive = len(true_positive_df)\n",
    "    false_positive = len(false_positive_df[false_positive_df['_merge'] == 'left_only'])\n",
    "    false_negative = len(false_negative_df[false_negative_df['_merge'] == 'left_only'])\n",
    "\n",
    "    if true_positive + false_positive > 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "\n",
    "    if true_positive + false_negative > 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0.0\n",
    "\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    " \n",
    "    print(f'Порог: {threshold:.1f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0.0:.4f}\\n')\n",
    "\n",
    "all_pairs = [(list1_title[i], list2_title[j]) for i in range(len(list1_title)) for j in range(len(list2_title))]\n",
    "\n",
    "all_pairs_df = pd.DataFrame(all_pairs, columns=['Ключ', 'Значение'])\n",
    "\n",
    "end_time = time.time()\n",
    "end_memory = process.memory_info().rss\n",
    "\n",
    "y_true = all_pairs_df.merge(title_to_title_true_df, on=['Ключ', 'Значение'], how='left', indicator=True)\n",
    "y_true['_merge'] = y_true['_merge'].map({'both': 1, 'left_only': 0})\n",
    "y_true = y_true['_merge'].values\n",
    "y_scores = cosine_similarities.flatten()    \n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print('\\nВремя, затраченное на обучение модели: ', end_time - start_time, ' секунд')\n",
    "print(f\"Использовано памяти: {end_memory - start_memory} байт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b56c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем график ROC-кривой\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkblue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})') # Изменен цвет на темно-синий\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show() \n",
    " \n",
    "# Построение Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(all_recalls, all_precisions, linestyle='-', color='darkblue', label='Precision-Recall Curve') # Убрали маркеры и изменили цвет\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af65d64",
   "metadata": {},
   "source": [
    "# Решение задачи сопоставления с помощью нормализованного расстояния Левенштейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b783ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "start_time = time.time()\n",
    "start_memory = process.memory_info().rss \n",
    "\n",
    "distances = []\n",
    "for title1 in list1_title:\n",
    "    for title2 in list2_title:\n",
    "        distance = 1 - fuzz.ratio(title1, title2) / 100\n",
    "        distances.append((title1, title2, distance))\n",
    "\n",
    "distances_df = pd.DataFrame(distances, columns=['list1_title', 'list2_title', 'distance'])\n",
    "\n",
    "merged_df = distances_df.merge(title_to_title_true_df, left_on=['list1_title', 'list2_title'], right_on=['Ключ', 'Значение'], how='left')\n",
    "merged_df['true_match'] = merged_df['Ключ'].notna().astype(int)\n",
    "\n",
    "thresholds = [0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "metrics = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    merged_df['pred_match'] = (merged_df['distance'] <= threshold).astype(int)\n",
    "    precision = precision_score(merged_df['true_match'], merged_df['pred_match'])\n",
    "    recall = recall_score(merged_df['true_match'], merged_df['pred_match'])\n",
    "    f1 = f1_score(merged_df['true_match'], merged_df['pred_match'])\n",
    "    metrics.append((threshold, precision, recall, f1))\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, columns=['Threshold', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "end_time = time.time()\n",
    "end_memory = process.memory_info().rss \n",
    "\n",
    "print('\\nВремя, затраченное на обучение модели: ', end_time - start_time, ' секунд')\n",
    "print(f\"Использовано памяти: {end_memory - start_memory} байт\")\n",
    "\n",
    "fpr, tpr, roc_thresholds = roc_curve(merged_df['true_match'], -merged_df['distance'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "precision, recall, pr_thresholds = precision_recall_curve(merged_df['true_match'], -merged_df['distance'])\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# ROC Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='darkblue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show() \n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='darkblue', lw=2, label=f'PR curve (area = {pr_auc:.2f})') \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
